{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home task: Supervised ML cover"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titanic - Machine Learning from Disaster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "cwd= os.getcwd()\n",
    "path = os.path.join(cwd,'data')\n",
    "\n",
    "def get_train_set():\n",
    "    fp = os.path.join(path, 'train.csv')\n",
    "    X = pd.read_csv(fp) \n",
    "    \n",
    "    return X\n",
    "\n",
    "X = get_train_set()\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading predict dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PassengerId',\n",
       " 'Pclass',\n",
       " 'Name',\n",
       " 'Sex',\n",
       " 'Age',\n",
       " 'SibSp',\n",
       " 'Parch',\n",
       " 'Ticket',\n",
       " 'Fare',\n",
       " 'Cabin',\n",
       " 'Embarked']"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_predict_set():    \n",
    "    fp = os.path.join(path,'test.csv')\n",
    "    df_predict = pd.read_csv(fp)\n",
    "\n",
    "    return df_predict\n",
    "\n",
    "df_predict= get_predict_set()\n",
    "list(df_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting NaN values to zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_nan_to_zero(df):\n",
    "    df = df.fillna(0)\n",
    "    return df\n",
    "\n",
    "X = convert_nan_to_zero(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get rid of irrelevant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_irrelevant_features(df): \n",
    "    cols_to_drop = [\n",
    "        \"PassengerId\",\n",
    "        \"Name\",\n",
    "        \"Ticket\",\n",
    "        \"Fare\",\n",
    "        \"Cabin\"\n",
    "    ]\n",
    "    df = df.drop(cols_to_drop, axis=1)\n",
    "    return df\n",
    "\n",
    "X = drop_irrelevant_features(X)\n",
    "y = X[\"Survived\"]\n",
    "\n",
    "# Remove the target variable from the training set\n",
    "X = X.drop(\"Survived\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding non-numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label encoding.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def label_encoder(df): \n",
    "    cols_to_encode = [\"Sex\", \"Embarked\"]\n",
    "    print ('label encoding.')\n",
    "    df = df.copy() # to avoid warning related to setting the copy...\n",
    "\n",
    "    for col in cols_to_encode:\n",
    "        le = LabelEncoder().fit(df[col].astype(str)) # convert to str first since le may fail due to difference type of data\n",
    "        df[col] = le.transform(df[col].astype(str))\n",
    "    return df\n",
    "\n",
    "X = label_encoder(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train set to evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape:  (891, 6)\n",
      "y.shape:  (891,)\n",
      "X_train.shape:  (712, 6)\n",
      "X_test.shape:  (179, 6)\n",
      "y_train.shape:  (712,)\n",
      "y_test.shape:  (179,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"X.shape: \", X.shape)\n",
    "print(\"y.shape: \", y.shape)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"X_train.shape: \", X_train.shape)\n",
    "print(\"X_test.shape: \", X_test.shape)\n",
    "print(\"y_train.shape: \", y_train.shape)\n",
    "print(\"y_test.shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def normalize(X_train, X_test):\n",
    "    print ('normalizing.')\n",
    "    scaler= MinMaxScaler()\n",
    "    X_train_scaled= scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    return X_train_scaled, X_test_scaled \n",
    "\n",
    "X_train_scaled, X_test_scaled  = normalize(X_train, X_test)\n",
    "type(X_train_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding best classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "def run_GridSearchCV(clf,grid_values, X_train_scaled, X_test_scaled, y_train, y_test= None):\n",
    "    print ('Running GridSearchCV.')\n",
    "    grid_clf = GridSearchCV(clf, param_grid=grid_values,scoring='f1')\n",
    "    grid_clf.fit(X_train_scaled, y_train)\n",
    "    print('Grid best parameter (max f1 ): ', grid_clf.best_params_) \n",
    "    print('Grid best score (f1): ', grid_clf.best_score_) \n",
    "\n",
    "    if not y_test is None:\n",
    "        test_score= grid_clf.score(X_test_scaled, y_test)\n",
    "        print(\"test f1= {}\".format(test_score))\n",
    "\n",
    "\n",
    "def run_all_classifiers(X_train_scaled, X_test_scaled, y_train, y_test=None, list_classifiers= None):\n",
    "    if list_classifiers is None or 'LogisticRegression' in list_classifiers:\n",
    "        print ('\\nLogisticRegression.')\n",
    "        clf = LogisticRegression(max_iter=10000)\n",
    "        grid_values = {'C': [0.005, 0.01,0.1, 1, 100, 10000, 100000]}\n",
    "        run_GridSearchCV(clf,grid_values, X_train_scaled,X_test_scaled,  y_train,  y_test= y_test)\n",
    "\n",
    "    if list_classifiers is None or 'DecisionTreeClassifier' in list_classifiers:\n",
    "        print ('\\nDecisionTreeClassifier')\n",
    "        clf = DecisionTreeClassifier()       \n",
    "        grid_values = {'max_depth': [2,5,7, 20, 50]}\n",
    "        run_GridSearchCV(clf,grid_values, X_train_scaled, X_test_scaled, y_train,  y_test= y_test)   \n",
    "\n",
    "    if list_classifiers is None or 'RandomForestClassifier' in list_classifiers:\n",
    "        print ('\\nRandomForestClassifier.')\n",
    "        clf = RandomForestClassifier()       \n",
    "        grid_values = {'n_estimators': [20,50]} #,200,300]}\n",
    "        run_GridSearchCV(clf,grid_values, X_train_scaled,X_test_scaled, y_train,  y_test= y_test)   \n",
    "\n",
    "    if list_classifiers is None or 'SVC_poly' in list_classifiers:\n",
    "        print ('\\nSVC_poly')\n",
    "        clf = SVC(kernel='poly')           \n",
    "        grid_values = {'C': [0.01]}# , 0.1, 1, 100, ]}\n",
    "        run_GridSearchCV(clf,grid_values, X_train_scaled, X_test_scaled, y_train,  y_test= y_test)   \n",
    "\n",
    "    if list_classifiers is None or 'SVC_rbf' in list_classifiers:\n",
    "        print ('\\nSVC_rbf')\n",
    "        clf = SVC(kernel='rbf')\n",
    "        grid_values = {'C': [0.005, 0.01]}# , 0.02, 0.03, 0.1, 1, 100, 10000], 'gamma':[0.001, 0.01, 0.1]}\n",
    "        run_GridSearchCV(clf,grid_values, X_train_scaled, X_test_scaled, y_train,  y_test= y_test)   \n",
    "\n",
    "    if list_classifiers is None or 'NB' in list_classifiers:\n",
    "        print ('\\nNB')\n",
    "        clf =  GaussianNB().fit(X_train_scaled, y_train)\n",
    "        train_f1 = f1_score(y_train, clf.predict(X_train_scaled))\n",
    "        print(\"train set f1= {}\".format(train_f1))\n",
    "        if not y_test is None:\n",
    "            test_f1 = f1_score(y_test, clf.predict(X_test_scaled))\n",
    "            print(\"train set f1= {}\".format(test_f1))\n",
    "\n",
    "            \n",
    "    if list_classifiers is None or 'GradientBoostingClassifier' in list_classifiers:\n",
    "        print ('\\nGradientBoostingClassifier.')\n",
    "        clf = GradientBoostingClassifier() # learning_rate = 0.03)       \n",
    "        grid_values = {'max_depth': [3,5,7]}\n",
    "        run_GridSearchCV(clf,grid_values, X_train_scaled,X_test_scaled, y_train,  y_test= y_test)   \n",
    "\n",
    "    if list_classifiers is None or 'MLP' in list_classifiers:\n",
    "        print ('\\nMLP.')\n",
    "        clf = MLPClassifier(hidden_layer_sizes = [50]) #, 100])\n",
    "        grid_values = {'alpha' : [0.001, 0.01, 0.1, 1, 10]}\n",
    "        run_GridSearchCV(clf,grid_values, X_train_scaled,X_test_scaled, y_train,  y_test= y_test)   \n",
    "\n",
    "    if list_classifiers is None or 'xgboost' in list_classifiers:\n",
    "        print ('\\nxgboost.')\n",
    "        clf = XGBClassifier().fit(X_train_scaled, y_train)\n",
    "        y_predicted = clf.predict(X_test_scaled)\n",
    "        print ('f1_score  = {:.2}'.format(f1_score(y_test, y_predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LogisticRegression.\n",
      "Running GridSearchCV.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid best parameter (max f1 ):  {'C': 100}\n",
      "Grid best score (f1):  0.7083895170064711\n",
      "test f1= 0.7534246575342465\n",
      "\n",
      "DecisionTreeClassifier\n",
      "Running GridSearchCV.\n",
      "Grid best parameter (max f1 ):  {'max_depth': 50}\n",
      "Grid best score (f1):  0.712069712475673\n",
      "test f1= 0.7172413793103449\n",
      "\n",
      "RandomForestClassifier.\n",
      "Running GridSearchCV.\n",
      "Grid best parameter (max f1 ):  {'n_estimators': 50}\n",
      "Grid best score (f1):  0.7242111756905032\n",
      "test f1= 0.762589928057554\n",
      "\n",
      "NB\n",
      "train set f1= 0.7145557655954632\n",
      "train set f1= 0.7320261437908496\n",
      "\n",
      "GradientBoostingClassifier.\n",
      "Running GridSearchCV.\n",
      "Grid best parameter (max f1 ):  {'max_depth': 3}\n",
      "Grid best score (f1):  0.7325192524933138\n",
      "test f1= 0.7591240875912408\n",
      "\n",
      "xgboost.\n",
      "f1_score  = 0.78\n"
     ]
    }
   ],
   "source": [
    "list_classifiers= [\n",
    "    'LogisticRegression',\n",
    "    'DecisionTreeClassifier',\n",
    "    'RandomForestClassifier',\n",
    "    'NB',\n",
    "    'GradientBoostingClassifier', \n",
    "#   'MLP', \n",
    "    'xgboost', \n",
    "    \n",
    "]\n",
    "run_all_classifiers(X_train_scaled, X_test_scaled, y_train, y_test, list_classifiers= list_classifiers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting results on predict dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>897</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>898</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>899</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>901</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         1\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         1\n",
       "5          897         0\n",
       "6          898         1\n",
       "7          899         0\n",
       "8          900         1\n",
       "9          901         0"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "clf = XGBClassifier().fit(X_train_scaled, y_train)\n",
    "\n",
    "# Preprocessing predict dataset\n",
    "df_predict = convert_nan_to_zero(df_predict)\n",
    "\n",
    "PassengerId = df_predict[\"PassengerId\"]\n",
    "df_predict = drop_irrelevant_features(df_predict)\n",
    "df_predict = label_encoder(df_predict)\n",
    "\n",
    "y_predicted = clf.predict(df_predict)\n",
    "\n",
    "result_df = pd.DataFrame({'PassengerId': PassengerId, 'Survived': y_predicted})\n",
    "result_df.to_csv('submission.csv', index=False)\n",
    "\n",
    "result_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
